{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c02b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52ad6f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=256\n",
    "ALL_RESULTS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530764bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history, type='accuracy'):\n",
    "    df = pd.DataFrame(history.history)\n",
    "    if type == 'accuracy':\n",
    "        df[['accuracy','val_accuracy']].plot()\n",
    "    else:\n",
    "        df[['loss','val_loss']].plot()\n",
    "\n",
    "def build_model(n_layers=1, units=[16], input_shape=(1,), l_rate=None, dropout=0, regularizer=None ):\n",
    "    if(len(units) != n_layers):\n",
    "        raise Exception(\"The list of units cannot be applied to the n_layers specified!\")\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(units[0], activation = 'relu', kernel_regularizer=regularizer, input_shape = input_shape))\n",
    "    if dropout != 0:\n",
    "        model.add(layers.Dropout(dropout))\n",
    "    \n",
    "    for i in np.arange(2,n_layers+1):\n",
    "        model.add(layers.Dense(units[i-1], kernel_regularizer=regularizer, activation = 'relu'))\n",
    "        if dropout != 0:\n",
    "            model.add(layers.Dropout(dropout))\n",
    "    \n",
    "    model.add(layers.Dense(10, activation = 'softmax'))\n",
    "    \n",
    "    if(l_rate != None and l_rate != 0):\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=l_rate)\n",
    "    else:\n",
    "        optimizer = 'rmsprop'\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def fit_evaluate(model, x_train, y_train, x_val, y_val, epochs, n_layers, units, dropout, regularization):\n",
    "    history = model.fit(x_train, \n",
    "                        y_train,\n",
    "                        epochs = epochs ,\n",
    "                        batch_size = BATCH_SIZE,\n",
    "                        validation_data = (x_val, y_val), verbose=0)\n",
    "    \n",
    "    val_loss, val_acc = model.evaluate(x_val, y_val, verbose=0 )\n",
    "    train_loss, train_acc = model.evaluate(x_train, y_train, verbose=0 )\n",
    "    print('Training --> Accuracy: %s - Loss: %s'%(train_acc, train_loss))\n",
    "    print('Validation --> Accuracy: %s - Loss: %s'%(val_acc, val_loss))\n",
    "    print('-----\\n')\n",
    "    \n",
    "    ALL_RESULTS.append({\n",
    "        'n_layers': n_layers,\n",
    "        'units': units,\n",
    "        'epochs': epochs,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'dropout': dropout,\n",
    "        'regularization': regularization,\n",
    "        'val_acc': val_acc,\n",
    "        'val_loss': val_loss,\n",
    "        'train_acc': train_acc,\n",
    "        'train_loss': train_loss,\n",
    "        'history': history\n",
    "    })\n",
    "    \n",
    "    return train_acc, train_loss, val_acc, val_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa185c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = x_train.reshape((len(x_train), 32*32*3))\n",
    "x_test = x_test.reshape((len(x_test), 32*32*3))\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "input_shape=(x_train.shape[1], )\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4268435",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_partial, x_val , y_train_partial, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d647e52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2828 - accuracy: 0.1122 - val_loss: 2.1870 - val_accuracy: 0.1460\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.1608 - accuracy: 0.1618 - val_loss: 2.1653 - val_accuracy: 0.1640\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.1194 - accuracy: 0.1704 - val_loss: 2.0971 - val_accuracy: 0.1851\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.0968 - accuracy: 0.1822 - val_loss: 2.0841 - val_accuracy: 0.1822\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.0820 - accuracy: 0.1863 - val_loss: 2.0662 - val_accuracy: 0.1846\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.0708 - accuracy: 0.1848 - val_loss: 2.0591 - val_accuracy: 0.1890\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.0647 - accuracy: 0.1873 - val_loss: 2.1182 - val_accuracy: 0.1793\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.0615 - accuracy: 0.1875 - val_loss: 2.0691 - val_accuracy: 0.1883\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.0562 - accuracy: 0.1875 - val_loss: 2.0755 - val_accuracy: 0.1843\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.0536 - accuracy: 0.1874 - val_loss: 2.0438 - val_accuracy: 0.1881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf8b7d1d90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = build_model(n_layers=1, units=[8], input_shape=input_shape, l_rate=None )\n",
    "model.fit(x_train_partial, \n",
    "          y_train_partial,\n",
    "          epochs = 10 ,\n",
    "          batch_size = BATCH_SIZE,\n",
    "          validation_data = (x_val, y_val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55c71af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 907us/step - loss: 2.0438 - accuracy: 0.1881\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_val, y_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67d798b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with 1 layers and 32 units, trained on 40 epochs\n",
      "\n",
      "Training --> Accuracy: 0.4404999911785126 - Loss: 1.6174325942993164\n",
      "Validation --> Accuracy: 0.41290000081062317 - Loss: 1.660278558731079\n",
      "-----\n",
      "\n",
      "Evaluating model with 2 layers and 32 units, trained on 40 epochs\n",
      "\n",
      "Training --> Accuracy: 0.4509750008583069 - Loss: 1.5855913162231445\n",
      "Validation --> Accuracy: 0.42649999260902405 - Loss: 1.635727882385254\n",
      "-----\n",
      "\n",
      "Evaluating model with 3 layers and 32 units, trained on 40 epochs\n",
      "\n",
      "Training --> Accuracy: 0.4295249879360199 - Loss: 1.6120386123657227\n",
      "Validation --> Accuracy: 0.4050000011920929 - Loss: 1.6588902473449707\n",
      "-----\n",
      "\n",
      "Evaluating model with 3 layers and 64 units, trained on 40 epochs\n",
      "\n",
      "Training --> Accuracy: 0.4914250075817108 - Loss: 1.455230712890625\n",
      "Validation --> Accuracy: 0.4611000120639801 - Loss: 1.5310434103012085\n",
      "-----\n",
      "\n",
      "Evaluating model with 3 layers and 128 units, trained on 40 epochs\n",
      "\n",
      "Training --> Accuracy: 0.5245500206947327 - Loss: 1.353035569190979\n",
      "Validation --> Accuracy: 0.47269999980926514 - Loss: 1.4961953163146973\n",
      "-----\n",
      "\n",
      "Evaluating model with 3 layers and 256 units, trained on 40 epochs\n",
      "\n",
      "Training --> Accuracy: 0.5506250262260437 - Loss: 1.2654918432235718\n",
      "Validation --> Accuracy: 0.47620001435279846 - Loss: 1.5204212665557861\n",
      "-----\n",
      "\n",
      "Evaluating model with 3 layers and 256 units, trained on 50 epochs\n",
      "\n",
      "Training --> Accuracy: 0.6011999845504761 - Loss: 1.1265606880187988\n",
      "Validation --> Accuracy: 0.5020999908447266 - Loss: 1.474514126777649\n",
      "-----\n",
      "\n",
      "Evaluating model with 3 layers and 256 units, trained on 60 epochs\n",
      "\n",
      "Training --> Accuracy: 0.6107000112533569 - Loss: 1.0836601257324219\n",
      "Validation --> Accuracy: 0.49079999327659607 - Loss: 1.4909460544586182\n",
      "-----\n",
      "\n",
      "Overfitting achieved\n"
     ]
    }
   ],
   "source": [
    "#let's try \n",
    "ALL_RESULTS = []\n",
    "curr_val_acc = 0\n",
    "curr_train_acc = 0\n",
    "last_val_acc = 0\n",
    "last_train_acc = 0\n",
    "units = 32\n",
    "n_layers = 1\n",
    "epochs = 40\n",
    "max_layers = 3\n",
    "max_units = 256\n",
    "\n",
    "while True:\n",
    "    last_val_acc = curr_val_acc\n",
    "    last_train_acc = curr_train_acc\n",
    "    model = build_model(n_layers=n_layers, units=[units]*n_layers, input_shape=input_shape, l_rate=0.0001 )\n",
    "    print('Evaluating model with %s layers and %s units, trained on %s epochs\\n'%(n_layers, units, epochs))\n",
    "    \n",
    "    curr_train_acc, curr_train_loss, curr_val_acc, curr_val_loss = fit_evaluate(model, \n",
    "                                                                                x_train_partial, \n",
    "                                                                                y_train_partial, \n",
    "                                                                                x_val, \n",
    "                                                                                y_val, \n",
    "                                                                                epochs, \n",
    "                                                                                n_layers, \n",
    "                                                                                units,\n",
    "                                                                                0,\n",
    "                                                                                0)\n",
    "    \n",
    "\n",
    "        \n",
    "    if curr_val_acc < last_val_acc and curr_train_acc > last_train_acc:\n",
    "        print('Overfitting achieved')\n",
    "        break\n",
    "    \n",
    "    if n_layers == max_layers:\n",
    "        if units == max_units:\n",
    "            epochs += 10\n",
    "        else:\n",
    "            units = units*2\n",
    "    else:\n",
    "        n_layers += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c412fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with 3 layers and 256 units, trained on 200 epochs with 0.2 dropout \n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Try adding different rates of dropout\n",
    "\n",
    "hyper_dropout = [0.2]\n",
    "#hyper_dropout = [0.05]\n",
    "epochs = 200\n",
    "for dropout in hyper_dropout:\n",
    "    model = build_model(n_layers=n_layers, units=[units]*(n_layers), input_shape=input_shape, l_rate=None, dropout=dropout)\n",
    "    print('Evaluating model with %s layers and %s units, trained on %s epochs with %s dropout \\n '%(n_layers, units, epochs, dropout))\n",
    "    fit_evaluate(model, \n",
    "                 x_train_partial, \n",
    "                 y_train_partial, \n",
    "                 x_val, \n",
    "                 y_val, \n",
    "                 epochs, \n",
    "                 n_layers, \n",
    "                 units,\n",
    "                 dropout,\n",
    "                 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a913e76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABFfklEQVR4nO2dd3hc1bW33z3qvVvdlmzLNrblhm0M2BRTDITeSwglQCCEQOAS0rghucmXS0gguYFACJ3QTe/VYIoxlntvsq1iSVaxetfs7489xzOSZqRRHY283ufRMzOn7qORfmed3157baW1RhAEQfB/bL5ugCAIgjA4iKALgiCMEkTQBUEQRgki6IIgCKMEEXRBEIRRQqCvTpyYmKizsrJ8dXpBEAS/ZPXq1RVa6yR363wm6FlZWeTl5fnq9IIgCH6JUmqfp3ViuQiCIIwSRNAFQRBGCSLogiAIowSfeeiCIByetLW1UVRURHNzs6+bMqIJDQ0lIyODoKAgr/cRQRcEYVgpKioiKiqKrKwslFK+bs6IRGtNZWUlRUVFZGdne72fWC6CIAwrzc3NJCQkiJj3gFKKhISEPj/FiKALgjDsiJj3Tn9+R70KulIqUym1TCm1RSm1WSl1q5ttrlBKbVBKbVRKfaOUmtnnlnjJ9tI6/vLhdqoaWofqFIIgCH6JNxF6O3CH1noqsAC4WSk1tcs2e4Djtda5wP8Ajw5uM53kl9fz4LJdlNVKh4ogCP0jMjLS100YEnrtFNValwAljvd1SqmtQDqwxWWbb1x2+RbIGOR2HiIixDS5oaV9qE4hCILgl/TJQ1dKZQGzgZU9bPZD4H0P+9+glMpTSuWVl5f35dSHOCTorR392l8QBMFCa82dd97J9OnTyc3N5aWXXgKgpKSE4447jlmzZjF9+nS+/PJLOjo6uPrqqw9t+8ADD/i49d3xOm1RKRUJvArcprWu9bDNiRhBX+huvdb6URx2zNy5c/s1911ESAAgEbogjAZ+9/Zmtux3Kyf9ZmpaNL89a5pX27722musW7eO9evXU1FRwbx58zjuuON4/vnnWbJkCb/+9a/p6OigsbGRdevWUVxczKZNmwCorq4e1HYPBl5F6EqpIIyYP6e1fs3DNjOAx4BztNaVg9fEzkQEi+UiCMLg8NVXX3HZZZcREBBAcnIyxx9/PKtWrWLevHk8+eST3HPPPWzcuJGoqCjGjx9Pfn4+t9xyCx988AHR0dG+bn43eo3QlcmdeRzYqrW+38M2Y4HXgCu11jsGt4mdEQ9dEEYP3kbSw81xxx3H8uXLeffdd7n66qu5/fbb+cEPfsD69ev58MMPeeSRR3j55Zd54oknfN3UTngToR8LXAksVkqtc/ycoZS6USl1o2Ob/wYSgH861g9ZXdzIhr1cG/A+7Q0Hh+oUgiAcJixatIiXXnqJjo4OysvLWb58OfPnz2ffvn0kJydz/fXXc91117FmzRoqKiqw2+1ccMEF/OEPf2DNmjW+bn43vMly+QroMcNda30dcN1gNaongiu28t9Bz/Jk3RJgznCcUhCEUcp5553HihUrmDlzJkop/vznP5OSksLTTz/NfffdR1BQEJGRkTzzzDMUFxdzzTXXYLfbAfjTn/7k49Z3x/9quQSb/NGO5jofN0QQBH+lvr4eMKMx77vvPu67775O66+66iquuuqqbvuNxKjcFf8b+h8SBYBuqfdxQwRBEEYW/ifojgidVonQBUEQXPE/QQ9xCLpE6IIgCJ3wP0F3ROgB7Q0+boggCMLIwv8E3eGhB7SJoAuCILjif4IeEESbCiZQInRBEIRO+J+gA622cII6Gn3dDEEQhBGFfwp6YDghHRKhC4Iw9PRUO33v3r1Mnz59GFvTM34p6B2BEYTpJto67L5uiiAIwojB/0aKAu2BEUTQTGNLBzHhfnlPEgQB4P1fQOnGwT1mSi6c/r8eV//iF78gMzOTm2++GYB77rmHwMBAli1bxsGDB2lra+MPf/gD55xzTp9O29zczE033UReXh6BgYHcf//9nHjiiWzevJlrrrmG1tZW7HY7r776KmlpaVx88cUUFRXR0dHB3XffzSWXXDKgywY/FXQdHEGEKqG+tZ2Y8CBfN0cQBD/ikksu4bbbbjsk6C+//DIffvghP/3pT4mOjqaiooIFCxZw9tln92mi5oceegilFBs3bmTbtm2ceuqp7Nixg0ceeYRbb72VK664gtbWVjo6OnjvvfdIS0vj3XffBaCmpmZQrs1PBT2KSPbQKCV0BcG/6SGSHipmz57NgQMH2L9/P+Xl5cTFxZGSksLPfvYzli9fjs1mo7i4mLKyMlJSUrw+7ldffcUtt9wCwJQpUxg3bhw7duzg6KOP5o9//CNFRUWcf/755OTkkJubyx133MFdd93FmWeeyaJFiwbl2vzTrwiOJEI1Uy+CLghCP7joootYunQpL730EpdccgnPPfcc5eXlrF69mnXr1pGcnExz8+BMRH/55Zfz1ltvERYWxhlnnMFnn33GpEmTWLNmDbm5ufzmN7/h97///aCcyy8jdFtoFOE00SjzigqC0A8uueQSrr/+eioqKvjiiy94+eWXGTNmDEFBQSxbtox9+/b1+ZiLFi3iueeeY/HixezYsYOCggImT55Mfn4+48eP56c//SkFBQVs2LCBKVOmEB8fz/e//31iY2N57LHHBuW6/FbQI2imvrnN100RBMEPmTZtGnV1daSnp5OamsoVV1zBWWedRW5uLnPnzmXKlCl9PuaPf/xjbrrpJnJzcwkMDOSpp54iJCSEl19+mWeffZagoCBSUlL41a9+xapVq7jzzjux2WwEBQXx8MMPD8p1Ka37NVfzgJk7d67Oy+vfxEZVH/2Z+G/+yJtnrOKc+ZMGuWWCIAwlW7du5YgjjvB1M/wCd78rpdRqrfVcd9v7pYceFGYmZ21tkhK6giAIFn5puQRHGEFvb6z1cUsEQTgc2LhxI1deeWWnZSEhIaxcudJHLXKPfwq6I0LvaBJBFwR/RGvdpxxvX5Obm8u6deuG9Zz9scP90nJRjhK6Mq+oIPgfoaGhVFZW9kuwDhe01lRWVhIaGtqn/fwyQrdmLbKLoAuC35GRkUFRURHl5eW+bsqIJjQ0lIyMjD7t45+CHmwidFplGjpB8DeCgoLIzs72dTNGJX5puVgRuhJBFwRBOIR/CrpjXlGbTEMnCIJwCL8W9IA2idAFQRAs/FPQbTZaVKjMKyoIguCCfwo60BIQTrDMKyoIgnAIvxX0toAIgu0i6IIgCBZ+K+jtgRGE2puw22VwgiAIAvixoHcERRCpmmhsk5rogiAI4MeCbg8yE0U3yKxFgiAIgB8Lug6OIoImEXRBEAQHfivoKiSSSNVMQ4tYLoIgCODPgh4aaSyXVonQBUEQwI8FPSAkmnDVQkNTi6+bIgiCMCLoVdCVUplKqWVKqS1Kqc1KqVvdbKOUUv+nlNqllNqglJozNM11EhhmKi42y6xFgiAIgHflc9uBO7TWa5RSUcBqpdTHWustLtucDuQ4fo4CHna8DhmB4WbWojYRdEEQBMCLCF1rXaK1XuN4XwdsBdK7bHYO8Iw2fAvEKqVSB721LgQ7BL1dpqETBEEA+uihK6WygNlA15lR04FCl89FdBd9lFI3KKXylFJ5A52tJCQ8BoC2Jpm1SBAEAfog6EqpSOBV4Datdb/CYq31o1rruVrruUlJSf05xCECQo2HrpslQhcEQQAvBV0pFYQR8+e01q+52aQYyHT5nOFYNnRY84q2SIQuCIIA3mW5KOBxYKvW+n4Pm70F/MCR7bIAqNFalwxiO7vjmORCtcgkF4IgCOBdlsuxwJXARqXUOseyXwFjAbTWjwDvAWcAu4BG4JpBb2lXQmSiaEEQBFd6FXSt9VeA6mUbDdw8WI3yCkeE3tEslosgCAL48UhRgsKwY6OloQZzPxEEQTi88V9BV4q2wHAC2xupqG/1dWsEQRB8jv8KOkBwJJE0sbtcfHRBEAS/FnRbaBQRqpn88gZfN0UQBMHn+LWgB4bFEmdrkAhdEAQBPxd0lTSJybZiEXRBEAT8XNBJySVeV1N9oMjXLREEQfA5fi/oADE122huk6noBEE4vBkVgj5N7WVvpXSMCoJweOPfgh4aQ2tUJlNt+yTTRRCEwx7/FnTAljqDI9Q+dh+QjlFBEA5v/F7QA9Nmkm0rpbDsgK+bIgiC4FP8XtBJnYENDWWbfd0SQRAEn+L/gu7oGI06uFWKdAmCcFjj/4IenU5LUAwT7Hsoq23xdWsEQRB8hv8LulI0JUxjqm0fu6RjVBCEwxj/F3QgLHMWU1Qh6/aV+7opgiAIPmNUCHpIxixCVRv7d23wdVMEQRB8xqgQdDLmAhBeuhK7XTpGBUE4PBkdgp4wgbqILBZ1rGLHAZljVBCEw5PRIeiAnnQ6R9s2s25Xoa+bIgiC4BNGjaBHzTyLYNVB05aPfN0UQRAEnzBqBF1lHkW9LZrUss993RRBEASfMGoEnYBASsYs4qj2PMqqJR9dEITDj9Ej6EDg1O8Rp+rZvWaZr5siCIIw7IwqQc+YeyatOhC2v+frpgiCIAw7o0rQg8Jj2Boyg4yKr3zdFEEQhGFnVAk6QEPyXDLaC6mtqfJ1UwRBEIaVUSfo8TnzsSnNjnXf+LopgiAIw8qoE/TsGccCULlzpY9bIgiCMLyMOkEPiU2jKiCRoLL1vm6KIAjCsDLqBB2gJnYa41p2UFkvE14IgnD4MCoFPWTckWSrUvK2F/i6KYIgCMPGqBT05ElHYVOagi0rfN0UQRCEYWNUCnpAxhwA2grX+rglgiAIw8eoFHQix1Afkkxa0zZKapp83RpBEIRhoVdBV0o9oZQ6oJTa5GF9jFLqbaXUeqXUZqXUNYPfzL5jT5lJrtrDlzsrfN0UQRCEYcGbCP0p4LQe1t8MbNFazwROAP6qlAoeeNMGRmT2XCbYSvh47U5fN0UQBGFY6FXQtdbLgZ7G0WsgSimlgEjHtu2D07z+Y0s3PnrdnjWU1jT7uDWCIAhDz2B46A8CRwD7gY3ArVpru7sNlVI3KKXylFJ55eXlg3DqHkiZAcAUtY/X1xYP7bkEQRBGAIMh6EuAdUAaMAt4UCkV7W5DrfWjWuu5Wuu5SUlJg3DqHogcA8GRzIuu4bU1RWitzfKyzVAjAi8IwuhjMAT9GuA1bdgF7AGmDMJxB4ZSEJfNrMgqdh6oZ1NxLbS3wL9PggemwX8ugO3v+7qVgiAIg8ZgCHoBcBKAUioZmAzkD8JxB058NikdJQQH2nh1TRFU7YH2Jsg5BQ5shRcuhYZKX7dSEARhUPAmbfEFYAUwWSlVpJT6oVLqRqXUjY5N/gc4Rim1EfgUuEtrPTJyBeOzCajex6lTEnlzXTGtZdvM8hN/BWfcZ95X7/Nd+wRBEAaRwN420Fpf1sv6/cCpg9aiwSR+PNjb+OGMEN7Z1MbmDXnMBkjIAeW4l9UUgSMjRhAEwZ8ZnSNFLeKyAZgVWcWcsbGU5W9ER6dBSCTEZJptaop82EBBEITBY3QLevx4AFTVHm48fgIpbQWUh4wz68LiIDAMaiXjRRCE0cHoFvToNAgIhoN7OHnKGHJsJayoSTApjEpBTAbUFPq6lYIgCIPC6BZ0WwDEZUFVPraGMiJoIq8hkc+3OwY1xWSI5SIIwqhhdAs6GB+9ai9U7ACgNiKbez/YRnuHXQRdEIRRxegX9PjxcHDPIUE/95QT2FZax3MrC0zHaH2ZGXAkCILg5xwGgp4NrfWw72sIjuSEI2dw7MQE/vrRdupDk802tft920ZBEIRB4DAQdJPpwq7PIDEHZbNxz1nTaGjt4KUdjvouYrsIgjAKGP2C7shFp6UGEicBkJMcxQ+OHsd/tnWYdSLoQ0dbE3T4vJqyIBwWjH5Bjx3rHBWamHNo8XWLxlOiE8wHEfSh498nwfL7fN0KQTgsGP2CHhhsslngUIQOkB4bxvycdKqIwS656ENH1W7zIwjCkDP6BR2ctouLoANcMjeTIns81ft7KA5ZXQD3ZkHJ+qFr32ilvRXam6G51tctEYTDgsND0OPHgwpwdpA6OHnqGMptSTRXFXjed98KaDoIhd8NcSNHIS21nV8FQRhSDg9BP+YWuOAxCAzptDgkMICIMVlEt5RRWedh3tHSDeb14N6hbeNIoKMditf0bZ+2Zmj0MOVsc03nV0EQhpTDQ9ATJsD0892uGj9hCpGqmVe+3ux+37JN5vVwEPQtb8C/F/ctL3/5n+Gxk92vOyToEqELwnBweAh6D4zJmADAm1+s5L/f3ERLe4dzpdZQutG8PxwEvXY/oKGhD/OTVBeY3401Z6srYrkIwrBy2Au6VRf9mukBPLNiHxc/soK65jazrq4EGishKMKzaI0mmhzWSUud9/s014LucL+PFZm31IHdPvD2CYLQIyLoMekAXJxj4+Er5rC+qIaHljnS7KzoPOcUUz6gL5GrP9LYD0G3tm066GadFZlraO3DMQVB6Bci6BFjwBYENUWcnpvK+bPTeeLrPRRWNToFfcqZ5nW4bJfmGt88DfQnQrdEu8lNx6irdy4+uiAMOSLoNhuMmQIbXoaaYv5ryWRsCu77cLsR9LgsSJ1hth0OQW+ph/unwdr/DP25utJU7WhDH8TXEuoeI/Q+HlMQhH4hgg5w7iMmKn3uQtJCW7l+0XjeWr+f5qL1kJJrygeAKcM71NQWG3sif9nQn6sr/bJcHJks7gRdInRBGFZE0AFSpsOl/zE101+8gh8tzCQzwk5w7V7akqZBUBhEpQ5PhF5XYl4LVw39ubpi2Sat9d5tr3UvHrpL/rlE6IIw5IigW4w/Ac55CPZ+SeRnv+GvxwdhQ/PCvlizPi7bKegd7fDxf0PlENQoqSszrzUFUFc6+Mf3hNZ9j9BbG0A7slc8Rei2IMd7GVwkCEONCLorMy+FY2+FvMeZv+vvADyyPZxX8godc5M6LJe9y+Hrv8OmVwe/DVaEDlDkZZSuNZRuGth52xqhwzFzk7eC7hp1W/571/XRaea9CLogDDki6F056bcwYTEUfIMOjSVr/CR+88YmyoNSoW6/Geq+5U2z7VBE6PVlEBgGAcHeC/q+r+GRY6FkQ//P6xphe2uPuPri7ob/N9ceyvMXy0UQhh4R9K7YAuCCxyF+PCpzPv93+RyiQgN5aqtjfVU+bH3bvK/cNfjnrysxufEpM6Aoz7t9rHYMpK67qyD3K0L3kOUS6UgLlU5RQRhyRNDdER4PP1oOFz5JYmQIfzg3lxVVUWbduufM6NHo9M51vrWGf8yFlf8a2LnrSk0HbMY8Uyiro633fazaK42V/T+v1SEaGOa9oFsiHRjmwUOvgdAYCI2WCF0QhgERdE+EREFIJACnTU9h6jSTi96x6glTCmDuNUbErMi2eh9U7oSdHw3svHWlEJkMGXOhvQnKPBQNc6W22LwORNCt64gb1/cIPXas507R0GgIiZYIXRCGARF0L/mv8xbSSCgB7Y3Ujl0MydPNisouZQKKV/d/lKfWjgg9BTLnm2Xe+OhWhO5utKa3WIIcO7bvgh43rrugt7eYTtaQaInQBWGYEEH3ktiIECNcwK93TOTd4nCzwvKvrSyTpoP9z1dvqTVReVSK6UyMTO6boA+G5RI71oxW9QYr6o51CLrrjcxaFxojEbogDBMi6H0gPDkHHRhOQ+aJ3PZRNXZsTh+9bBMEhpr3xau9P2hdmVMIrbzzqFRQyvjo+76Bhl6EusayXAYQoTcehOBICE8wI1W9qY7YUgsoM2erva3zgCQrIg+JNqIuEbogDDki6H3h+LtQFz/Fv687jiUzMinUSVQVbDHrSjdCzqlG1L2d9Wf/Orh/Cuz+1Hy2BD0y2bxOOw9qCuFv0+H9X3j2qa1KhgMR9KYqCIszfQfg3WjR5loj2OHxjmO4tM/KOxcPXRCGDRH0vpA6AyYtIcCm+NP5uZQGplO+bwsHqypMp2jaLJNuuN9LQV/7rBlpWfCt+ewaoQPkXgg/XglTz4Hv/gWf39v9GJbdYgsceKeoq6B746O31BnBDnMj6J0i9GgZWCQIw4AIej+JCg1iwpSZZNj3888XHQONknMh/UgTeXe093yA9hbYuNS8tzpUrVGiUcnO7cZMgfMegbFHQ7GbvHQrwyVx0sA7RcPj+yjojgg9LM55DItDHrojQm+tA3tH92OMVL59GHZ+4utWCEKfEEEfAIljpxKhWojZ/wUAhcHjjaC3N0H5tp533vEBNFdDdIZT0OvLjI9tiaorqTNNx2tXUbQi9JRcI6j9Fc2mKhNph0Sbz94IenONI0J3I+hdPXRvjzlS+OJeWPuMr1shCH1CBH0gJJj5SK+NW89BojjjqV0sb8gw63rrGF33vLFW5l9nouyGShOhR6W43z5lhrlRVOzsvNwS9ORpxr7pr7XRzXLxwvNuqTXb9xahh0Y7t/cH2prNtfTWGS0II4xeBV0p9YRS6oBSymP1J6XUCUqpdUqpzUqpLwa3iSMYh6CH1+0lLHMW45Oi+MGblTQFRNJeuNpkimxc2r3GSv0B2PkxzLgYUmeZZWUbTcZLpAdBT51pXkvWd15eWwwRSU7fvT8do3a7eVoIjzdPCOBlhG5ZLrHms6cI3Yr6/aVjtN7Rl9E4CFMOtjb6l9Uk+DXeROhPAad5WqmUigX+CZyttZ4GXDQoLfMHYjJNES0gNGMmr/zoaG48fiKrWrMpXf8Rtf86DV79Ibx7R+f9Nr5iJlaeebmxSsDYLj1F6ImTTAZNN0Hfb8oQWJkm/ekYbakx0X1YfN+yXKxO0aAwM/zf9WbSXGtuDrYAzxF6fTk8cw7UljCisDqnBzqHrNbw4FxY8eDA2yQIXtCroGutlwM9hX2XA69prQsc2x8YpLaNfGwBpk46QPJ0ggNt/OL0KWTNWESGLoHSDeyImIsuWtW5tvm6FyBttunwjEiEqDQTxVujRN0REGhGp3oS9DA3gl5d6N2oVUuI+9spau3rWkK3uca5LsThoXeN0Au/hfzPoXBl7+caTlxH3nqTj++JxirzBFX43eC0SxB6YTA89ElAnFLqc6XUaqXUDzxtqJS6QSmVp5TKKy8vH4RTjwASJprXlOmHFo09+Uba5v+YZ2a/xK3VF6PQNG50VGgs3WjslZmXO4+RkmsGEFmjRD2ROhNKN3QWmdpiU3M8PMF8tjJdqvbA33Jh9VO9X4NllfQlbbGtGTpandF3WFwXy6XGuc5ThF5dYF6HcyIPC7sd2lvdr7Pao+3uc/+9pabQvFbs6P8xBKEPDIagBwJHAt8DlgB3K6UmudtQa/2o1nqu1npuUlLSIJx6BJA8zVgLiZOdy+LGEXTGn/jJucdz9zXns1ensP3zF2hq7YD1L5pysrkXOrdPyYVaR+lbywt3R+pMI4rVe83n1gZHpoyLoFsR+oGtgIblfzEpkj1hRehh8RAQ5Ki42Ivf7eqRQ3dBb3aJ3g956F06bKsdglfvA0Ff8SA8NM/9OtdJRnrz0avyPZc5tsoZV+V7VzVTEAbIYAh6EfCh1rpBa10BLAdmDsJx/YOFt5lSu4HBblcfMzEJ+6QzmNayjp8/u4yO9S/BpCVOzxucPjo4R4m6I9VUfDxku1jec3Q6BEcYP98S56p8xzZFpuRvT1hCbLUpJKr3CL25q6DHdu8UHckRetkmU3PHXd0a1/b05qO/fRu8ep37dZag29uHZz5a4bBnMAT9TWChUipQKRUOHAVs7WWf0UNwxKFsF0+MX3QpwaqDE/c+QEBjOQ9WzSNvr0u3hKug9xShj5lqRoQeEnTHoKLoNFP7JTzBGaFX5Zv874x58OX9nu0FcNo0VvqhN4JuibMny8U1Qg8MdUxy0TVC96GgW+esL3OzrgSCHdZTT53MzTVmtqh6D91GluUCYrsIw4I3aYsvACuAyUqpIqXUD5VSNyqlbgTQWm8FPgA2AN8Bj2mtBzjB5SgjYx5EjOH8gK9oDIzhuarJXPbvb/l0q0NM4rKd6YJRPUTogSEw5ghnGqTVeWfN2xkW3zlCj58Ax99lhGX9C56P21gFKOcAoL4IeifLpcrZCesaoSvlGP7fJUKv8aGgW0LuVtBLjZUGPVsuuz4x0XdbA7Q1dV9fU+RMQy3fPrD2CoIXeJPlcpnWOlVrHaS1ztBaP661fkRr/YjLNvdpradqradrrf82pC32R2w2mHIGAOFzLuWDO07miNRobvzPaj7ZUmbWJ0/3PErUldSZJkLXunOEDo5ME1dBHw8TT4a0OcZLdyc64BglGmuydsAh6L2kLTa7idA7Ws1k09Z66wYBRvhdLZfmGvOjbJ09695ob3H0DwwQ65zubiaugt7T4KLtHzjfu4vka4rMDTgqtfuAMEEYAmSk6HCRezEEhMCcHxATFsSzPzyKqanR3PTcap78eg/2aefDlDN7P07aHBM1rnzEROhh8SYPHJyWS3uricrjs010fMrvTDT8zT/cH7Oxypn2CH2M0B03INcCXa6TW1iExnSO0K0O0THTTMduW3Pv1w7muh9ZNLDsk7Ymp/3T1S5pqTN1Z2LHmvZ7itA72s3sVF07o12pKTKlhRNzRofl0tro/fck+AQR9OEi61j4ZdGh9MaYsCCeve4oFk5M5Hdvb+HyDTMoPOGB3o8z63Ij/B/8Aja8ZDpELcLjjbDUFJqUu/jxZnn2cTD1XOOlVxd2P2bTQad/Dg5B7yXLpVunqMvwf9fJLSy6zlpk+eeZjkwTbzNdCr41tdcHEvG62ixdz+ta8TI8wXOnaOG35kaUe7H53FXQ21vMsWMyzaCwip39n8lqpPDcRfD2rb5uhdADIujDSZdMmOjQIJ64eh5/vmAGm4prWfzXz/n50vXsOtBDdBwUBhc/A0fdZEZzWnYLGAFqOuicRckSdIBT/8e8fny3ieDzPzcDnJqqjeUS3tcI3bHenaB39det964RutVhmOGYaq/OjZfdFa2dNXIGIuiu5+p63kMVL1PMoC9PEfr29x3pp46B0V1LLlj9GzEZJqW1pca9X+8vaA0l62D3Z/5/YxrFBPq6AYc7SikunpfJokmJPPz5bl7OK+TlvCLmZ8VzRm4KZ+SmMiY6tPNOtgA4/X/NRNKx45zLwxNMZL5/rfnsKuixY2Hhz+Dz/2fKwlqTYgSGmX2SjnBuawm61saycUdLrZksO8DxJ+Qq6FYHb2gXy6VrhB4Y5hyQ5Y2PXrvfKYqVAxF0x7kCwzxH6NFpEJ7oTD3syo4PIGshxGWZz10jeWu/mAzz+wVju/Q0cGwk01BhAojWevPdxY3rfR9h2JEIfYSQGhPG78+Zztd3LeaOUyZR09TGPW9v4ej//YxbX1zLpmI3VRRzL3RaFuD0sYtWGVGN6DJ469ifGrtm+nlw6Qtw3acw6zKTVuiaOhkSZWyNngYkNdd0FmxL0BurvIvQqwsgNtOZpulNposVnduCBsdySZne3UPvFKEnuI/Qq/LNU9Dk001nsrJ1t1xcBT3RMc7On3101zx6b+a5FXyCROgjjITIEG45KYdbTsph14E6XvyukBdXFfLmuv18b0YqfzhnOnER7gcxHeqgK15tUiG7RtdBYXBpl0FGGXPhe/d33ta1JnpQl6cDC6t07qFzx4MKgO3vwYxLzLJOEbrLJBe2ACPoMZnmJmQL8s5DL15tth1/wgAtl1KTzz/mCNj2Xvd1VrZReKKJTLs+qVj16zOPMtcSFudZ0KPTTbppcGTf27z+RTNZyun/27f9hoKDe5zvC7/rPNJZGDFIhD6CmTgmit+cOZVvfrmY207O4aPNpZz6t+Us2+ZhIIvr3J7x2d6fqKvwe1MT3XXgEJibxZL/ZzI/3v+54zhdInRweu81hcYGstnM6FhvI/TkaeanKr/3WaE8UV9mzhmVZiJw12H5tfudtkhEonlS6fp7KN8OKGfk7Tqgy6KmECLGmBuiUibTpa+56BtfgbzHO1+n3e6bTJMqh6Cnz5UIfQQjgu4HRIcGcdvJk3jj5mOJDw/mmqdW8dCyXeiunVOuHZuu/nlf8aaErlU615UFN8KZf3N2EHaN0MHcbFobjADGZpplUSm9C7rdbqLV9CONONrbzDyunijdBI+eCJW7u6+rK3EIumMQl6vtUlfqtIHCE81rV3+8fJu5GQWHO7ZzJ+iOlEULK9OlL1TuNrn9rnbHd4/C32cMf431g3vNDTB7kSkQ52lMg+BTRND9iGlpMbz5k2M5Z1Ya9324nV+9vpH2DpfKi5blAgMTdNdJLjraTDZM12i4pUuEbjH3GrjgMZh2vrNsLphywQBb33KmTlodut4IeuVOY9mkHwkJOY5lu9xv21gFL15uJuve+lb39XVl5pzWKE7X7JO6EhdB95BjfmAbJE1xfvZK0HNMXR1vp+HraHOmdrpOZ7j3S9NeK4tmqFh6Lax/yfn54B7z1Jcx34yO3b9uaM8/Utj+ATw4f+C18YcJEXQ/IzQogAcunsXNJ07ghe8KOeehr3l3Qwkddu2YUCLIbDgYEXpLnfFx37gRdn7YeZvmWs+jWnMvhIueNHaKRUouZC2Clf+CKkfUHOMaofeS5WJ1iFoROriPeO0dZlKRuhJjeexZ3n2b+lIToVuF0CxB17pzTfoIh6C7/jN3tJubS5JLdc2ugq51d0FPm2NevbUrqgvMJCjQWdAt/34oi31V7YFNr8L6553LDu41GT0Zjk74w8V22fQqVGyH5ff5uiVeIYLuh9hsijuXTOEfl82msbWDm59fw+K/fs79n+ykPdRhu/TFQ++Kq9+9aal533WO1JYuQ/u94ZhbTLkCa8Rq7FjzGpXS+2jR4tWmYFZijrGWwuLdpy5+/r8mV/qMv8C088xAJNfCZO2tRnyjUp2Wi/V00HTQjHDtarm4ivXBvcYGcRehWxZY00FT38VV0DOPMh2xe79yf30bl8KGl52frWqZ4PTem2udNlNPdtNAyV9mXotWmxtkW5O5QcZlQ2SSEfaiw2DSDq1NQKBssOox9/bdCEME3Y85a2Yan9x+PA9fMYfUmFAe/GwnO+uDaSWIL8uC+n9gK/Ku3OWMcIvXONd3tJmaLe4sl56YeIrxkgtWmFK/VoR8yProwXYpXg1ps5z1Ztx50vYO84835Uw48irj97Y1dr4ZWdF4VLKJ4F2XHRol6tIpCp1TF61oeUwXQbe3O8sJuKYsWoREmijdnaB3tMF7d8KyPzqXWeKRkus8Z9lm5/qhjNB3OwS9tc7cTKxzWUFCxnwoXOV5gFHpRnODcqWuDDa9NiTNHTIqdpq/yRN+acp2fPp7X7eoV0TQ/ZwAm+L03FRevOFoVv7qZGITUylWKVz5RB6XPfotP1+6nlteWMuf3ttKTZOXkyxYgr72OTMoZuzRxo8+VEnR4QN37RTtDZsNFvzYvI/JcFoyveWitzaYTs70Oc5liRO7C/r+dWbU69RzzedxxwLK+M4WlnhHppiRu+EJLoK+v3N7giPM4KMGN4JuZbiAi/A7Inl3gg5mIFLxanM9ruR/btp9cK+zRk1VvnkiyVpk8tftHaaGOxhrbagE3d5hbuJjjzafi1Y5z2UNosqYZ4TOtTywKx/8Et64qXP20MqHYek1nksN+5I9y90/He5xzHefe6F5utzyhufJTEYIIuijiKSoEFLP+3+kX/EQd585lcKDjSzfUcGm4hr+/WU+J/31C95ev797dkxXgsJMTnltESTnwszLTPRp2QBWFktfI3SAmZcaK8MSB3BGxJ4Effcyk9Uy4STnsoQcaDjQucb6ro8BBRMWm8/h8SbCdfXRD0Xh1tNBsnP4/6FRoi416SMSO1su5duN998pB9/qPHX8Xg4Jembn68haaCL5rnOobnzF+d6qdV+VbyLipCnQ3mw89dKNxmpKmz10gr5/nbG/5l1n8uuLVjlTFq35c8efYF7Xv9h9/+pCcwPtaO18w7W8f+u1v6x5Fl6/afDKD5Rvh6fPgi/u7b5uz3LzHcZlG0EPi4NVjw/OeYcIEfTRRuY8gicezw8XZvPVXYv59lcnsey/TuCtnywkNSaUW15Yy8J7l/HL1zbyxY5y9+KulFOwci80HZHgtC52feI41/y+ty8oDK58DU7/s3NZb4K+/X2TMTPuGOeyQx2jLpkuOz82bbU6M8EUJiv8zhmBWbaOFYVHJjuXFXxrouKoLvVxukborh2i4EwXtayZg3vN6FvLg7dw56O3NsLWd+CIs8xnK3ukareZOMXy6su3GzFMmW6EfqgEPf8z8zr+BBOJF60yGS4h0c7rTJoEOUvg24e7P21scrFaXMXbem89ZfSHojx45zbTWbvvm/4fx5Xdjutd/ZT5LizsdnNjyj7O8f8QaSqDug6wGoGIoB8mTE+P4Y2bj+UvF81keno0b6/fz1VPfMfNz6+hst7NEH8r+p5+gRGVwDCnoG95w/xxW6LaV1Jndt63p9Gi9g5TNyXnZDPfqcWh1EVHFNhYZdo38eTO+2ctMh2dVideXanp5LLKIkSlmAjd3mFGuU5a0rmIWrjL8H97h7E/XDtErW3AZT7XzWYUqq3Lv5c7H33HB6YDdf4NppO4ZJ0zZTF+vBFP65gHtponprgsaCjvLqaDwe5lkDLDPJlkzDM3sJL15pyuA9AW3W5sojXPOpdpbVId0480nnOZQ8Trypy2Vmk/Bb2p2lg2UWnm5p73RP+O05XdyyAo3FzLRpdO6bJNxv7KPs65LDbTfbXSEYQI+mFEgE1x4ZEZ/OvKuay5+xTuOm0Kn2w5wKkPLGfZ9i7eZkQijD3G/BEHBJoOyeI1Zh7Tgm9h2rmD17CeRosWrzaCOvmMzsvjsowtZE12sfszQEPOKZ23G3e0EXDLdqkrNWJuda5GjjFis+8bI8hHdKlJH5HonOSiusDYH90i9C4eetlm5wQZXenqo29cap4Wxh0LqbNMhF5dYKyZ+PHmMT8yxZQoaG8yEbqVv39wkDNdWurN08yEE81nK0WxcGVniwxg7ALjs3/zD2cWUdkmKN9qSjwnT3WJyh2vYXGdI/SONsesT70MktLaROY1xXDhE6b+0Na3Bp4b3tFmbq4zLzM3ym8fcVo51t9L1iLn9rFjTT/LCJ7wWwT9MCU40MZNJ0zg7VsWMiY6lGufWsWjy3c7LZgLHzf/PBbpR5oRgpteBTRMPWdwG+QpF337+0a4J57UeXlgsBHH7x41ArnzY6e/7EpojFm240PzGG0N+7eITDH+/NpnTVQ5scsNIdylhK6VPtg1Qg+OMPs2VppOv4ZyMwOVO1x99PLtplTC9AvMDSZtlnmkP1Qt0zFXbdJkKHZ0xiVPd3rZfbVdtDYDZTwVXdv3tfldjHcIevqRgCMqd5cGu/B2089iRbYbXjKW0rTzTTtLN5pzWsI+7XzzhGOdP+9J+M8F8MrVPY883b8GNr9usk0y58GR1xiPvrfJz3ujKM88HU04ERbcZG5GVkfo3i8hYSLEuMw3EJNpkgSsmcJGICLohzmTU6J49aajOX16Cv/vvW3c8Oxq7lq6gWvfquT298t4fmUBuw7UG1Fsb4av/25K7XaNUgdKYo6Jklc+2rnDa/v7xjt3nYDD4oLHTAT9/CVGGCcsdkbersy5ytyMvnu089B+cHaObn7d3DRCIjvvG5FgUh9bG91nuIBzgu6GSmcE6ilCt3z0F78PD803+868zKxLneVsCzgHh1k3EFug+b1b0bIl6Ha7dyNH96+BFy6BFQ+5X5//ufH+rQyX0GhjHYHzJuJKzikmsn3zZvjX8bD2P5BzqqMzeoa5wdWVGkGPGeu8mVm/xx0fGGtv69vwzLnda8pbbHrNWHLzrzefx0wxT495T5pr7y/5y8zTW9ZCc1MNT4R374BHTzB/T67ROTjHTVgjePtCR3vP0xkOEiLoAuHBgTx42RxuPSmHr3ZWsGz7Acpqm1m+s4Jfvb6Rk+//gtu/cRTmbDgwuHaLxal/NB1x798JL19pJsKuyjdRU1e7xSJyDFyx1ERrTVXd7RaLOT8wQvPJb01+d1SXCB3MMayOSVcsO+W7R80/eVSqKZnbbTvH4CLLIx7jQdBDImHe9WYGqzP+Aj/Jc9aEt54udn5sUhMjHXny1s0zcbKp3BgebzpvLUFf8zQ8MA32fEmPFDiya1Y/6d7myP/cWCmuFTYz5prXrpYLmJvRFS/D4t+Yzu6Weph7rVlnXVPpRvM7Scl1lmgu3WQsp71fwewrzaji/WvgidOMreKK3e642Z7c+fc+91rzNLPn856vuSfyPze/87A4c82Lbjc3lZAok9Wy6I7O21u1h/rjo3/0a/jHHO9LP/QTKZ8rAGb06c9OmcTPTnFGn1pr9lU28sHmUv71+S6qdCTxqp6S9CWkujnGgbpm4sODCQzoR5wQkQCXvQTfPgSf3GOitkCHsEw+zfN+SZPNfisehEketlMKzn4Q/rnACL8l4uC0X1SA+/2taPyT35rXI852fw5r+r+yzUb0XTNtuuKpHG54vIlkawpMZ6jVCWlF6JZIKmUE1hotuv5FYwW88WO46WvP4wOKvgOUiTB3fWI6gC3qyuDAFucMTBbZx5taPl1tJovoNDjuTvPjWmbYekIp+s50XE871zxxBIaZp5jwBNNZnXOKsTwikuD5S+GJJXDl685O88KVxuI4+Z7O5516NrwfD2uecaap9oXmWmO5LLzNuezom82PJ6IzOPT76ws1xaYTt6MVNr8Bc67se3u9RCJ0wSNKKbISI7jx+Al8+YuTqEqcx1Y9jhOeLuXvn+ykuc0Z5b25rphj/vQZ5z/8DXsr+pl9YbOZyOhnm+HcR4xPP/fa3uvSjDva1Hl3FzlbRCXDWX83761HZ2s5mMdu12qVrsf++R64fRvcvhUufNL98a189Z46RL0hbaZ5db3mMUeYkbVWJyWYGYMO7jXRYuG35umitsjMNdt00FgH92Z1LtlbuMp0+kaM6Z5PbXUCWjnmFtMvgNs2ds7N94RrFkxojOm83fCyudmk5Bo7zOos3fmRmfHKSkXNWgjXvGtsvSeWQNkWs3zza+bGPvn0zucKDDF197e969mq6Ym9X5laOVZ/gTcEBpubtacBVZ746gHzO4jOMLbUECKCLnhFZEggE294ltibPuDkqck88MkOTvrrF7y5rpgnv97DrS+uY1paNPsqG/ne/33JK3mFvQ9g8kRUislkOP9RONOLibO9ZerZcP2yzlFoSJTxsI/5qef9wuONoEWnOafc67ZNgukQLd82MEG3fHSrQ9Q6/80r4cirncvisoygb3YMpz/l98YiWPcc/H2miQibqh2d2BiPvbbIZNMceZURVNcsmT2fGxFOndm5PUp5J+buSMl1PkVYdkvydBOh7/zY3DwCQ1yufSZc+6Hxy5+7yAzQ2vyGieLdFYKb/X0T9brWwPGW/GXmaaGvYylix3aO0KsLPU9TCOb3vuZpk/lz1A3m5juQyVl6QQRd8J6QKFJT0njo8jm8eMMCYsODuPXFdfzu7S0smZbMSz86mvdvXcS09BjuXLqBCx7+hrUFB33d6s6kz+k+C9N5j5g894EQnuCYkanNdBT2F8tH7/pUEj++cx5+XJaJZr/7t8ltjx8Px99lOvJSZsCPvjTR79Z3zPaFjjz8jHnmxqCU8dLBWCX5X5ica3edyv3FEvGQaGeqZUqueYKoKXDf55EwwfjyzdXw75NMn830Czwcf7r5fa191lyD1vD1/8GuT3tul91uIvuuNxRviM3sLOivXAX/PMY5wrcrX/3NROeL7oAZlxprbwijdBF0oV8sGJ/AWz9ZyH0XzuCOUybx0OVzCA0KIC02jBeuX8C9F+RSUNXEef/8htteXMuBWh/MsjOcuNaiH0iEnrXQ/PNP+V7P21mdlDWFTsELCIKr3zE/KdPNMQ5sNp3LRatMamXKDFNjZtLpJoqvKTLrawqNXz6YWIKektvdWwfTUe2O1Jlw0dMm/TMowoxK9cTs75uIf/9a+Phu8/Pi5c7UT3cUrTK+/PTz+3Y9YCL02mLTqdxca87TUgPPnmfsrcrd8P5d8PBC+PN4+O5fptxFXJax9yYtgfVu5hcYJETQhX4TYFNcNDeTW07K6dQRGmBTXDJvLJ/feQI3nziB9zaWsvivX/CvL3ZzsKG1hyP6MZag24L6P4IWTMR40n+79/Ndcc06mXae+22sm8K294yIpc1yjoI99X8cteOvdw5/74uf7A2ugm5hCXry9M453l3JORkuexHOedA5M5Q7pl9oPPal15hBTrO+bzpYX7jccymJza+bm5unTvSeiMk0qZd1JabDV9tNtpIKgH8vNpksqx434n3E2XDSb83UjBazrzRjIazyGYOMZLkIQ0ZkSCB3LpnChUdm8ru3N/On97fx5w+3c+zERM6akcrpualEhoySP0FL0JOmdLZGhoqYTECZnHFPwhiXZeyfza+ZVEErjxuMtfG9++H1G0wnZXS6WTbYbVz0X51vOKExMPl7ztGoPTHJQwTvSlisEc6NL5u+kbP/YZ5KHj8VXrgMzrzf9EtYTwh2uyldkXNK36uFQudc9IJvjZDPvNT0Tbx7u3nKmXtt59RYV3JOMZ3Shd/2nL3VT0bJf5MwkslOjODJq+exeX8t72wo4d2N+7lz6QbufnMTJx+RzILxCczKjGVSchTBgX760GgJ+kDslr4QFGpSBbMX9bzdlO/BF440SdcsGYCZl5hc7PXPmyyZrpOFDxSl4KS7uy+/7PnuywbCSXcbi2nBj02mVEounP9vM3PVoyeYm+yiO2DGxUZI60o8P9X0xiFBL4R9K8y5QqJM9s61H/S+f0CQ6eDu7Qmsn4igC8OCUorp6TFMT4/hrtMms6agmjfWFvP+phLe2WCG/AfYFGPjw5mQFEFOchRTUqKYlRnLuIQIH7feCyKTAQWpM4bvnIt/3fs2roLuLqPjjPtMjZgjrxrctg0nsWPh2Fs7LzviTLhjm8mSWf0kvHa9EfKaImPR9MduAWeN+8pdphyDNZCqLwyRmAOofqeWDZC5c+fqvLyRXSxeGHq01hQdbGJtYTXbS2vJL29gd3k9+eUNtNvN3+ZR2fFcftRYTpg8hpiwoE77qsGOKgfCvm9M1kVQmK9b4kRr+NsM4/Xevrn37Ucj7a3w+o+M9WQLMjntlzzb+36euC/HPJGVb4WLnxn8uka9oJRarbWe626dROiCT1FKkRkfTmZ8OMx01iFvbbeTX1HPZ9sO8MJ3Bdz64joA0mPDSIsNpbS2mdKaZqalxXDnkskcOzHRwxmGEdd67SMFpeB7fzUpjocrgcGm7k9otKl73nU0bF+JHesslmbVvRkhSIQujHjsds3KPVWsK6xmS0ktZTXNpMSEkhQVwvsbS9hf08zR4xO4YsFYTj4imdCgQcylFkYPWpvUQtf5YPvDK1ebTJn4CfDTNb1uPthIhC74NTab4ugJCRw9oXt9lDuXTOa5lQX8e3k+P3l+LVEhgRwzMYGJYyKZkBTJ2PhwMuLCCQxQ7K9u4kBtC1PTokmLHUG2iDA8KDVwMQdnx+i4kRWdgwi64OeEBgXww4XZXH1MFit2V/L62mLWFh7kk60H6LB7fvqcmhrNmTNTufqYLMKD5d9A6APWXLEjzG4BEXRhlBBgUyzMSWRhjvHSW9vtFFQ1UnSwkcKDTbR32EmPDSMhMpi8vQf5eEsZf/5gO09/s5f/OnUyuRkxVNWbQU9zs+L9N31SGHrGLjBRen+qPA4xvXroSqkngDOBA1prD9OwgFJqHrACuFRrvdTTdhbioQu+ZvW+Kn7/zlbWF1Z3Wh4fEczZM9PITY8hONBGTFgQx0xI6F9ZYEEYZAbqoT8FPAg808MJAoB7gY/600BB8AVHjovn9ZuO4Yud5TS2dBAfEUx9SztvrCvm+e8KaG13zoaTGR/GzSdM5NzZ6W47XbXWVDW0Eh8RPLJSKYXDCq+yXJRSWcA7niJ0pdRtQBswz7GdROiCX1Pf0k5lfQttHXZ2HWjg4c93sb6oBoCYsCCSokJIjQklLSaMxrYOVu2porS2mXlZcfzp/FwmjnFT7lUQBoEhzXJRSqUD5wEnYgRdEPyeyJDAQ3VmJo6JYsm0ZL7aVcG6gmrK61s4UNtCSW0z20sPEGBTzMuOJzshnKdX7OP0v3/JebPTCbDZaGnv4KIjM91m6AjCYDMYnaJ/A+7SWtt7e9RUSt0A3AAwduzYHrcVhJGEUopFOUksyknqcbsfHJPFH9/dyvsbSwkNDqC13c47G0p49MojOWHymG7bt3XY2VBUw8o9lcSEBXH+7AzCgiWPXugfA7ZclFJ7AEvJE4FG4Aat9Rs9HVMsF+FwoLqxlSseW8nOA/Xce0EuTa128vZWsa+qkYr6Fkprmmlx8eoTIoK5dmE2l87LJCGyj5MvCIcFPVkug+Khu2z3FOKhC0InLFHfvL8WgMTIYHLGRJEYFUJKdAhzxsYxPzue3eUNPLRsF1/sKCcoQHHSlGTOn5POcZOSDnXEaq3psGvJuDmMGZCHrpR6ATgBSFRKFQG/BYIAtNaPDGI7BWFUEhsezAs3LOCbXZVMSo4kOzHCbSZMQmQI87Pns720jlfyCnl9bTEfbC4lPDiAYycm0tDSzpaSWhpa2slNj2FedjxZCRFEhwYRYIN9lY3srWxgWloMl88fi83W/RztHXa5GYxipJaLIIxQ2jrsrNhdyUdbSlm+o4K48CCmpkUTGRLI6n0H2VhcQ1tH5//f6NBAapvbmZcVx70XzCAtNoz6lnZW7K5k6eoivtxZzpHj4vj+gnGcNj2FkEDx6/2NAVsuQ4EIuiAMjOa2Dqob26htbqO13U5mfDjRoYG8uqaY37+9mdrmzvNWpsWEsviIMXy5s4J9lY2kxoRyz9nTWDItxUdXIPQHEXRBOMwoq23mlbxClFJEhQYyISmSBeMTCLAp7HbNl7sq+NN7W9lWWsepU5O5/KixTE2LJj48mKKDTeypaKDwYCPFB5tobO3grJlpzMuKk0FTIwARdEEQutHWYeexL/fwt092HMq0sSlwrWkWHGgjQCma2jqYkhLFEanRlNU2U9vcxtxx8SyeMoakqBA2769le2ktDa0dtLbbSYsN47pF2USHDsP8qocZIuiCIHiktrmNLftr2VpSS0V9C+MSIhifGMHYhHASI0Jobu/grXX7ef67AirrW0mJCSUk0MbqfQc7pVyGBNqICg0iOEBRUttMQkQwP18yhXNnpx8qdlbV0MqXO8uZnBLFlJR+TNIsiKALgjD4NLV2sCK/grrmdqalRZOdGEmAI7NmU3ENv31rM6v3HSQ4wMbklCjCggPI21uFXZvqmNctzOa2kydRUNXIlzvLiQgJ5Izc1E7TDArdEUEXBGHY0Vrz6dYDrNpXxebiWg42tnLi5DGcOCWJV/KKeHFVIcEBNlo7nFF+cKCN4yclERxgo6apjaAAxYSkSMYnRRIREkBQgI2kqBBmZ8YetumXIuiCIIw4vs2v5K31+5mZEcNxk5Ior2vh1dVFfLb9AMEBpmxxU5ud/PL6TtYOQFx4EIunJHPWzFQW5SRhU/Dlzgoe+WI34cGBXDAnncVHjKG51U5RdSMHalsor2+htqmN6NAgEqOCSY0JIyshwm2phabWDkKDbCOyE1gEXRAEv8Vu15TUNtPU2kG73U5+eQMfbynj061l1Da3kxwdQkpMGOsLq0mPDaOtw86BuhYCbKrHWassUmNCGRMdSlJkMFrDttI6iqubmDgmkquOyeLcWWnY7VDX0kZydChBPn4yEEEXBGHU0dLewWdbD7B0dRF7Kxu4+pgsLp6XSYBSfLWrghX5lSRFhpAWG0ZydChJkSHEhAdR29RGRX0LxdVN7K1oIL+igfK6FirqW7HbNZNToshKjODz7QfY4CiZbDEhKYL7L57FzMxYt22qaWzjia/3sKOsjsz4cMbGh7N4yphBncNWBF0QBKGPaK1ZU1DNN7sqCAsOINCm+NfyfA7UtXD5/LFUNrTw3Z6DAMwZG0tabBivrimirrmdcQnhlNQ009pux6bgpCOSufDIDGZnxjImOnRA7RJBFwRBGARqmtr43VubeW1tMemxYczPjkcpWFtQzZ6KBk6dmsxtJ09ialo0drtmb2UDS1cX8XJeIRWOOWuTokL40XHjuW7R+H61QQRdEARhEGlsbSc8uHNtw7YOu0d/vbXdzrrCajbvr2FTcS3HTUrknFnp/Tr3kM5YJAiCcLjRVcyBHjtLgwNtzM+OZ352/FA2i8MzkVMQBGEUIoIuCIIwShBBFwRBGCWIoAuCIIwSRNAFQRBGCSLogiAIowQRdEEQhFGCCLogCMIowWcjRZVS5cC+fu6eCFQMYnN8zWi6HrmWkYlcy8ikP9cyTmud5G6FzwR9ICil8jwNffVHRtP1yLWMTORaRiaDfS1iuQiCIIwSRNAFQRBGCf4q6I/6ugGDzGi6HrmWkYlcy8hkUK/FLz10QRAEoTv+GqELgiAIXRBBFwRBGCX4naArpU5TSm1XSu1SSv3C1+3pC0qpTKXUMqXUFqXUZqXUrY7l8Uqpj5VSOx2vcb5uq7copQKUUmuVUu84PmcrpVY6vp+XlFLBvm6jNyilYpVSS5VS25RSW5VSR/vr96KU+pnj72uTUuoFpVSoP30vSqknlFIHlFKbXJa5/S6U4f8c17VBKTXHdy3vjodruc/xd7ZBKfW6UirWZd0vHdeyXSm1pK/n8ytBV0oFAA8BpwNTgcuUUlN926o+0Q7cobWeCiwAbna0/xfAp1rrHOBTx2d/4VZgq8vne4EHtNYTgYPAD33Sqr7zd+ADrfUUYCbmmvzue1FKpQM/BeZqracDAcCl+Nf38hRwWpdlnr6L04Ecx88NwMPD1EZveYru1/IxMF1rPQPYAfwSwKEFlwLTHPv806F5XuNXgg7MB3ZprfO11q3Ai8A5Pm6T12itS7TWaxzv6zCikY65hqcdmz0NnOuTBvYRpVQG8D3gMcdnBSwGljo28YtrUUrFAMcBjwNorVu11tX46feCmVoyTCkVCIQDJfjR96K1Xg5UdVns6bs4B3hGG74FYpVSqcPSUC9wdy1a64+01u2Oj98CGY735wAvaq1btNZ7gF0YzfMafxP0dKDQ5XORY5nfoZTKAmYDK4FkrXWJY1UpkOyrdvWRvwE/B+yOzwlAtcsfq798P9lAOfCkwz56TCkVgR9+L1rrYuAvQAFGyGuA1fjn9+KKp+/C3zXhWuB9x/sBX4u/CfqoQCkVCbwK3Ka1rnVdp00e6YjPJVVKnQkc0Fqv9nVbBoFAYA7wsNZ6NtBAF3vFj76XOEyklw2kARF0f+T3a/zlu+gNpdSvMTbsc4N1TH8T9GIg0+VzhmOZ36CUCsKI+XNa69cci8usx0TH6wFfta8PHAucrZTai7G+FmN86FjHoz74z/dTBBRprVc6Pi/FCLw/fi8nA3u01uVa6zbgNcx35Y/fiyuevgu/1ASl1NXAmcAV2jkYaMDX4m+CvgrIcfTYB2M6EN7ycZu8xuExPw5s1Vrf77LqLeAqx/urgDeHu219RWv9S611htY6C/M9fKa1vgJYBlzo2MxfrqUUKFRKTXYsOgnYgh9+LxirZYFSKtzx92Zdi999L13w9F28BfzAke2yAKhxsWZGJEqp0zBW5dla60aXVW8BlyqlQpRS2ZiO3u/6dHCttV/9AGdgeoZ3A7/2dXv62PaFmEfFDcA6x88ZGO/5U2An8AkQ7+u29vG6TgDecbwf7/gj3AW8AoT4un1eXsMsIM/x3bwBxPnr9wL8DtgGbAKeBUL86XsBXsD4/22Yp6cfevouAIXJfNsNbMRk9/j8Gnq5ll0Yr9zSgEdctv+141q2A6f39Xwy9F8QBGGU4G+WiyAIguABEXRBEIRRggi6IAjCKEEEXRAEYZQggi4IgjBKEEEXBEEYJYigC4IgjBL+P2rSM7pFpXFHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(ALL_RESULTS)\n",
    "df\n",
    "plot_results(df.iloc[20].history,'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b63adfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_layers</th>\n",
       "      <th>units</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>regularization</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4129</td>\n",
       "      <td>1.660279</td>\n",
       "      <td>0.440500</td>\n",
       "      <td>1.617433</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbfcffa8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4265</td>\n",
       "      <td>1.635728</td>\n",
       "      <td>0.450975</td>\n",
       "      <td>1.585591</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbf5f0ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>1.658890</td>\n",
       "      <td>0.429525</td>\n",
       "      <td>1.612039</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbf5ce1e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4611</td>\n",
       "      <td>1.531043</td>\n",
       "      <td>0.491425</td>\n",
       "      <td>1.455231</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbf5d5c5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4727</td>\n",
       "      <td>1.496195</td>\n",
       "      <td>0.524550</td>\n",
       "      <td>1.353036</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbfc1e1c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4762</td>\n",
       "      <td>1.520421</td>\n",
       "      <td>0.550625</td>\n",
       "      <td>1.265492</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbfc57d8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5021</td>\n",
       "      <td>1.474514</td>\n",
       "      <td>0.601200</td>\n",
       "      <td>1.126561</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbfcb600...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4908</td>\n",
       "      <td>1.490946</td>\n",
       "      <td>0.610700</td>\n",
       "      <td>1.083660</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbfcf6fc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4472</td>\n",
       "      <td>2.221377</td>\n",
       "      <td>0.687275</td>\n",
       "      <td>0.883642</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbfccf84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4458</td>\n",
       "      <td>2.013547</td>\n",
       "      <td>0.640350</td>\n",
       "      <td>0.999004</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbfd1e13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4539</td>\n",
       "      <td>1.677096</td>\n",
       "      <td>0.624375</td>\n",
       "      <td>1.038470</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbf5c0cd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4579</td>\n",
       "      <td>1.546336</td>\n",
       "      <td>0.559100</td>\n",
       "      <td>1.220316</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbfc978a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4639</td>\n",
       "      <td>1.502489</td>\n",
       "      <td>0.523850</td>\n",
       "      <td>1.350122</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbfcb32a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4273</td>\n",
       "      <td>1.584412</td>\n",
       "      <td>0.469000</td>\n",
       "      <td>1.469409</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbf5d567...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4594</td>\n",
       "      <td>1.513934</td>\n",
       "      <td>0.506950</td>\n",
       "      <td>1.394077</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbf5bddc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4736</td>\n",
       "      <td>1.486632</td>\n",
       "      <td>0.537025</td>\n",
       "      <td>1.326462</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbf68acd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4164</td>\n",
       "      <td>1.659583</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>1.602644</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbf68c69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3237</td>\n",
       "      <td>1.878186</td>\n",
       "      <td>0.332350</td>\n",
       "      <td>1.859866</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbf69827...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>2.077582</td>\n",
       "      <td>0.239750</td>\n",
       "      <td>2.058919</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbf68663...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4632</td>\n",
       "      <td>1.501505</td>\n",
       "      <td>0.536150</td>\n",
       "      <td>1.333921</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fbf685cb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_layers  units  epochs  batch_size  dropout  regularization  val_acc  \\\n",
       "0          1     32      40         256     0.00               0   0.4129   \n",
       "1          2     32      40         256     0.00               0   0.4265   \n",
       "2          3     32      40         256     0.00               0   0.4050   \n",
       "3          3     64      40         256     0.00               0   0.4611   \n",
       "4          3    128      40         256     0.00               0   0.4727   \n",
       "5          3    256      40         256     0.00               0   0.4762   \n",
       "6          3    256      50         256     0.00               0   0.5021   \n",
       "7          3    256      60         256     0.00               0   0.4908   \n",
       "8          3    256      60         256     0.01               0   0.4472   \n",
       "9          3    256      60         256     0.02               0   0.4458   \n",
       "10         3    256      60         256     0.05               0   0.4539   \n",
       "11         3    256      60         256     0.10               0   0.4579   \n",
       "12         3    256      60         256     0.20               0   0.4639   \n",
       "13         2    256      60         256     0.20               0   0.4273   \n",
       "14         4    256      60         256     0.20               0   0.4594   \n",
       "15         3    256      60         256     0.20               0   0.4736   \n",
       "16         3    256      60         256     0.30               0   0.4164   \n",
       "17         3    256      60         256     0.40               0   0.3237   \n",
       "18         3    256      60         256     0.50               0   0.2362   \n",
       "19         3    256      80         256     0.20               0   0.4632   \n",
       "\n",
       "    val_loss  train_acc  train_loss  \\\n",
       "0   1.660279   0.440500    1.617433   \n",
       "1   1.635728   0.450975    1.585591   \n",
       "2   1.658890   0.429525    1.612039   \n",
       "3   1.531043   0.491425    1.455231   \n",
       "4   1.496195   0.524550    1.353036   \n",
       "5   1.520421   0.550625    1.265492   \n",
       "6   1.474514   0.601200    1.126561   \n",
       "7   1.490946   0.610700    1.083660   \n",
       "8   2.221377   0.687275    0.883642   \n",
       "9   2.013547   0.640350    0.999004   \n",
       "10  1.677096   0.624375    1.038470   \n",
       "11  1.546336   0.559100    1.220316   \n",
       "12  1.502489   0.523850    1.350122   \n",
       "13  1.584412   0.469000    1.469409   \n",
       "14  1.513934   0.506950    1.394077   \n",
       "15  1.486632   0.537025    1.326462   \n",
       "16  1.659583   0.444000    1.602644   \n",
       "17  1.878186   0.332350    1.859866   \n",
       "18  2.077582   0.239750    2.058919   \n",
       "19  1.501505   0.536150    1.333921   \n",
       "\n",
       "                                              history  \n",
       "0   <keras.callbacks.History object at 0x7fbfcffa8...  \n",
       "1   <keras.callbacks.History object at 0x7fbf5f0ea...  \n",
       "2   <keras.callbacks.History object at 0x7fbf5ce1e...  \n",
       "3   <keras.callbacks.History object at 0x7fbf5d5c5...  \n",
       "4   <keras.callbacks.History object at 0x7fbfc1e1c...  \n",
       "5   <keras.callbacks.History object at 0x7fbfc57d8...  \n",
       "6   <keras.callbacks.History object at 0x7fbfcb600...  \n",
       "7   <keras.callbacks.History object at 0x7fbfcf6fc...  \n",
       "8   <keras.callbacks.History object at 0x7fbfccf84...  \n",
       "9   <keras.callbacks.History object at 0x7fbfd1e13...  \n",
       "10  <keras.callbacks.History object at 0x7fbf5c0cd...  \n",
       "11  <keras.callbacks.History object at 0x7fbfc978a...  \n",
       "12  <keras.callbacks.History object at 0x7fbfcb32a...  \n",
       "13  <keras.callbacks.History object at 0x7fbf5d567...  \n",
       "14  <keras.callbacks.History object at 0x7fbf5bddc...  \n",
       "15  <keras.callbacks.History object at 0x7fbf68acd...  \n",
       "16  <keras.callbacks.History object at 0x7fbf68c69...  \n",
       "17  <keras.callbacks.History object at 0x7fbf69827...  \n",
       "18  <keras.callbacks.History object at 0x7fbf68663...  \n",
       "19  <keras.callbacks.History object at 0x7fbf685cb...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(ALL_RESULTS)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e8bc392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with 2 layers and 256 units, trained on 60 epochs with 0.2 dropout \n",
      " \n",
      "Training --> Accuracy: 0.4690000116825104 - Loss: 1.4694091081619263\n",
      "Validation --> Accuracy: 0.42730000615119934 - Loss: 1.584411859512329\n",
      "-----\n",
      "\n",
      "Evaluating model with 4 layers and 256 units, trained on 60 epochs with 0.2 dropout \n",
      " \n",
      "Training --> Accuracy: 0.5069500207901001 - Loss: 1.3940773010253906\n",
      "Validation --> Accuracy: 0.4593999981880188 - Loss: 1.5139338970184326\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Architecture tweaks\n",
    "\n",
    "hyper_layers=[2,4]\n",
    "#hyper_layers=[4]\n",
    "dropout = 0.2\n",
    "for l in hyper_layers:\n",
    "    model = build_model(n_layers=l, units=[units]*(l), input_shape=input_shape, l_rate=None, dropout=dropout)\n",
    "    print('Evaluating model with %s layers and %s units, trained on %s epochs with %s dropout \\n '%(l, units, epochs, dropout))\n",
    "    fit_evaluate(model, \n",
    "                 x_train_partial, \n",
    "                 y_train_partial, \n",
    "                 x_val, \n",
    "                 y_val, \n",
    "                 epochs, \n",
    "                 l, \n",
    "                 units,\n",
    "                 dropout,\n",
    "                 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbe62024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with 2 layers and 64 units, trained on 50 epochs with 0.05 dropout \n",
      " \n",
      "Training --> Accuracy: 0.481550008058548 - Loss: 1.4401447772979736\n",
      "Validation --> Accuracy: 0.44620001316070557 - Loss: 1.5396801233291626\n",
      "-----\n",
      "\n",
      "Evaluating model with 2 layers and 256 units, trained on 50 epochs with 0.05 dropout \n",
      " \n",
      "Training --> Accuracy: 0.5659499764442444 - Loss: 1.21165132522583\n",
      "Validation --> Accuracy: 0.46059998869895935 - Loss: 1.601852297782898\n",
      "-----\n",
      "\n",
      "Evaluating model with 2 layers and 512 units, trained on 50 epochs with 0.05 dropout \n",
      " \n",
      "Training --> Accuracy: 0.5921000242233276 - Loss: 1.171678900718689\n",
      "Validation --> Accuracy: 0.4645000100135803 - Loss: 1.74666166305542\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Layers dimension tweaks\n",
    "\n",
    "hyper_units = [64, 256, 512]\n",
    "\n",
    "for u in hyper_units:\n",
    "    model = build_model(n_layers=n_layers, units=[u]*(n_layers), input_shape=input_shape, l_rate=None, dropout=dropout)\n",
    "    print('Evaluating model with %s layers and %s units, trained on %s epochs with %s dropout \\n '%(n_layers, u, epochs, dropout))\n",
    "    fit_evaluate(model, \n",
    "                 x_train_partial, \n",
    "                 y_train_partial, \n",
    "                 x_val, \n",
    "                 y_val, \n",
    "                 epochs, \n",
    "                 n_layers, \n",
    "                 u,\n",
    "                 dropout,\n",
    "                 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "71876f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_layers</th>\n",
       "      <th>units</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>regularization</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>1.764235</td>\n",
       "      <td>0.392525</td>\n",
       "      <td>1.741370</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc08af1e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3703</td>\n",
       "      <td>1.765194</td>\n",
       "      <td>0.385150</td>\n",
       "      <td>1.747890</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc047fb4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>1.793092</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>1.777091</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc095fae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3846</td>\n",
       "      <td>1.739356</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>1.719907</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc099d1c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4175</td>\n",
       "      <td>1.665921</td>\n",
       "      <td>0.431050</td>\n",
       "      <td>1.628109</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc08e7ec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>1.561994</td>\n",
       "      <td>0.466150</td>\n",
       "      <td>1.489687</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc09af59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>30</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4716</td>\n",
       "      <td>1.484506</td>\n",
       "      <td>0.511175</td>\n",
       "      <td>1.372679</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc09ad23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>1.518238</td>\n",
       "      <td>0.516200</td>\n",
       "      <td>1.368284</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc088a5d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4219</td>\n",
       "      <td>1.748857</td>\n",
       "      <td>0.477875</td>\n",
       "      <td>1.508403</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc09caca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4590</td>\n",
       "      <td>1.537469</td>\n",
       "      <td>0.511925</td>\n",
       "      <td>1.354213</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc09826c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4406</td>\n",
       "      <td>1.553268</td>\n",
       "      <td>0.479100</td>\n",
       "      <td>1.430652</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc099de9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4165</td>\n",
       "      <td>1.628550</td>\n",
       "      <td>0.441250</td>\n",
       "      <td>1.572771</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0a2c83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2094</td>\n",
       "      <td>2.084756</td>\n",
       "      <td>0.207450</td>\n",
       "      <td>2.082693</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0a40dc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4466</td>\n",
       "      <td>1.616472</td>\n",
       "      <td>0.502100</td>\n",
       "      <td>1.390471</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0a2da5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>1.742594</td>\n",
       "      <td>0.529625</td>\n",
       "      <td>1.326141</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0a7d83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4529</td>\n",
       "      <td>1.681362</td>\n",
       "      <td>0.574600</td>\n",
       "      <td>1.190739</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0a7401...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4089</td>\n",
       "      <td>1.701468</td>\n",
       "      <td>0.447875</td>\n",
       "      <td>1.543736</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0a80d6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4618</td>\n",
       "      <td>1.847442</td>\n",
       "      <td>0.647450</td>\n",
       "      <td>0.990684</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0a40c6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>2.737271</td>\n",
       "      <td>0.679850</td>\n",
       "      <td>0.940598</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0896e0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>1.711816</td>\n",
       "      <td>0.530725</td>\n",
       "      <td>1.321090</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0acb6a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4321</td>\n",
       "      <td>1.607679</td>\n",
       "      <td>0.487800</td>\n",
       "      <td>1.407669</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0acb02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4532</td>\n",
       "      <td>1.518744</td>\n",
       "      <td>0.503675</td>\n",
       "      <td>1.370942</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0abf39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4333</td>\n",
       "      <td>1.598122</td>\n",
       "      <td>0.456025</td>\n",
       "      <td>1.540619</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0acfa9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>1.568575</td>\n",
       "      <td>0.593175</td>\n",
       "      <td>1.117331</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0ad717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4473</td>\n",
       "      <td>1.588198</td>\n",
       "      <td>0.527475</td>\n",
       "      <td>1.325629</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0ae935...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4505</td>\n",
       "      <td>1.550285</td>\n",
       "      <td>0.512850</td>\n",
       "      <td>1.353615</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0af2f7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4281</td>\n",
       "      <td>1.591221</td>\n",
       "      <td>0.461525</td>\n",
       "      <td>1.510206</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0afc9e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1.577240</td>\n",
       "      <td>0.561250</td>\n",
       "      <td>1.207889</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0b1976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4592</td>\n",
       "      <td>1.559665</td>\n",
       "      <td>0.541375</td>\n",
       "      <td>1.270109</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0b3b0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4537</td>\n",
       "      <td>1.724102</td>\n",
       "      <td>0.600975</td>\n",
       "      <td>1.108129</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0b40d8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4437</td>\n",
       "      <td>1.764841</td>\n",
       "      <td>0.584925</td>\n",
       "      <td>1.149752</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0b407e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4409</td>\n",
       "      <td>1.561773</td>\n",
       "      <td>0.489475</td>\n",
       "      <td>1.416107</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0b141d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4297</td>\n",
       "      <td>2.191055</td>\n",
       "      <td>0.648050</td>\n",
       "      <td>0.984861</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc0ac138...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4543</td>\n",
       "      <td>3.454185</td>\n",
       "      <td>0.793850</td>\n",
       "      <td>0.634457</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc08a2e4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>2.082419</td>\n",
       "      <td>0.731750</td>\n",
       "      <td>0.739107</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc08a2a0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4707</td>\n",
       "      <td>1.577355</td>\n",
       "      <td>0.618475</td>\n",
       "      <td>1.110683</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x7fc08cb20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_layers  units  epochs  batch_size  dropout  regularization  val_acc  \\\n",
       "0          1     32      10         256     0.00               0   0.3766   \n",
       "1          2     32      10         256     0.00               0   0.3703   \n",
       "2          3     32      10         256     0.00               0   0.3550   \n",
       "3          3     64      10         256     0.00               0   0.3846   \n",
       "4          3    128      10         256     0.00               0   0.4175   \n",
       "5          3    128      20         256     0.00               0   0.4379   \n",
       "6          3    128      30         256     0.00               0   0.4716   \n",
       "7          3    128      40         256     0.00               0   0.4633   \n",
       "8          3    128      40         256     0.01               0   0.4219   \n",
       "9          3    128      40         256     0.05               0   0.4590   \n",
       "10         3    128      40         256     0.10               0   0.4406   \n",
       "11         3    128      40         256     0.20               0   0.4165   \n",
       "12         3    128      40         256     0.50               0   0.2094   \n",
       "13         2    128      40         256     0.00               0   0.4466   \n",
       "14         4    128      40         256     0.00               0   0.4394   \n",
       "15         5    128      40         256     0.00               0   0.4529   \n",
       "16         5    128      40         256     0.00               0   0.4089   \n",
       "17         5    128      40         256     0.00               0   0.4618   \n",
       "18         5    128      40         256     0.00               0   0.4366   \n",
       "19         3    128      50         256     0.01               0   0.4399   \n",
       "20         3    128      50         256     0.05               0   0.4321   \n",
       "21         3    128      50         256     0.10               0   0.4532   \n",
       "22         3    128      50         256     0.20               0   0.4333   \n",
       "23         3    128      60         256     0.01               0   0.4724   \n",
       "24         3    128      60         256     0.05               0   0.4473   \n",
       "25         3    128      60         256     0.10               0   0.4505   \n",
       "26         3    128      60         256     0.20               0   0.4281   \n",
       "27         3    128      60         256     0.02               0   0.4610   \n",
       "28         2    128      60         256     0.01               0   0.4592   \n",
       "29         4    128      60         256     0.01               0   0.4537   \n",
       "30         5    128      60         256     0.01               0   0.4437   \n",
       "31         5    128      60         256     0.01               0   0.4409   \n",
       "32         5    128      60         256     0.01               0   0.4297   \n",
       "33         5    128      60         256     0.01               0   0.4543   \n",
       "34         5    128      60         256     0.05               0   0.4690   \n",
       "35         5    128      60         256     0.10               0   0.4707   \n",
       "\n",
       "    val_loss  train_acc  train_loss  \\\n",
       "0   1.764235   0.392525    1.741370   \n",
       "1   1.765194   0.385150    1.747890   \n",
       "2   1.793092   0.370000    1.777091   \n",
       "3   1.739356   0.394900    1.719907   \n",
       "4   1.665921   0.431050    1.628109   \n",
       "5   1.561994   0.466150    1.489687   \n",
       "6   1.484506   0.511175    1.372679   \n",
       "7   1.518238   0.516200    1.368284   \n",
       "8   1.748857   0.477875    1.508403   \n",
       "9   1.537469   0.511925    1.354213   \n",
       "10  1.553268   0.479100    1.430652   \n",
       "11  1.628550   0.441250    1.572771   \n",
       "12  2.084756   0.207450    2.082693   \n",
       "13  1.616472   0.502100    1.390471   \n",
       "14  1.742594   0.529625    1.326141   \n",
       "15  1.681362   0.574600    1.190739   \n",
       "16  1.701468   0.447875    1.543736   \n",
       "17  1.847442   0.647450    0.990684   \n",
       "18  2.737271   0.679850    0.940598   \n",
       "19  1.711816   0.530725    1.321090   \n",
       "20  1.607679   0.487800    1.407669   \n",
       "21  1.518744   0.503675    1.370942   \n",
       "22  1.598122   0.456025    1.540619   \n",
       "23  1.568575   0.593175    1.117331   \n",
       "24  1.588198   0.527475    1.325629   \n",
       "25  1.550285   0.512850    1.353615   \n",
       "26  1.591221   0.461525    1.510206   \n",
       "27  1.577240   0.561250    1.207889   \n",
       "28  1.559665   0.541375    1.270109   \n",
       "29  1.724102   0.600975    1.108129   \n",
       "30  1.764841   0.584925    1.149752   \n",
       "31  1.561773   0.489475    1.416107   \n",
       "32  2.191055   0.648050    0.984861   \n",
       "33  3.454185   0.793850    0.634457   \n",
       "34  2.082419   0.731750    0.739107   \n",
       "35  1.577355   0.618475    1.110683   \n",
       "\n",
       "                                              history  \n",
       "0   <keras.callbacks.History object at 0x7fc08af1e...  \n",
       "1   <keras.callbacks.History object at 0x7fc047fb4...  \n",
       "2   <keras.callbacks.History object at 0x7fc095fae...  \n",
       "3   <keras.callbacks.History object at 0x7fc099d1c...  \n",
       "4   <keras.callbacks.History object at 0x7fc08e7ec...  \n",
       "5   <keras.callbacks.History object at 0x7fc09af59...  \n",
       "6   <keras.callbacks.History object at 0x7fc09ad23...  \n",
       "7   <keras.callbacks.History object at 0x7fc088a5d...  \n",
       "8   <keras.callbacks.History object at 0x7fc09caca...  \n",
       "9   <keras.callbacks.History object at 0x7fc09826c...  \n",
       "10  <keras.callbacks.History object at 0x7fc099de9...  \n",
       "11  <keras.callbacks.History object at 0x7fc0a2c83...  \n",
       "12  <keras.callbacks.History object at 0x7fc0a40dc...  \n",
       "13  <keras.callbacks.History object at 0x7fc0a2da5...  \n",
       "14  <keras.callbacks.History object at 0x7fc0a7d83...  \n",
       "15  <keras.callbacks.History object at 0x7fc0a7401...  \n",
       "16  <keras.callbacks.History object at 0x7fc0a80d6...  \n",
       "17  <keras.callbacks.History object at 0x7fc0a40c6...  \n",
       "18  <keras.callbacks.History object at 0x7fc0896e0...  \n",
       "19  <keras.callbacks.History object at 0x7fc0acb6a...  \n",
       "20  <keras.callbacks.History object at 0x7fc0acb02...  \n",
       "21  <keras.callbacks.History object at 0x7fc0abf39...  \n",
       "22  <keras.callbacks.History object at 0x7fc0acfa9...  \n",
       "23  <keras.callbacks.History object at 0x7fc0ad717...  \n",
       "24  <keras.callbacks.History object at 0x7fc0ae935...  \n",
       "25  <keras.callbacks.History object at 0x7fc0af2f7...  \n",
       "26  <keras.callbacks.History object at 0x7fc0afc9e...  \n",
       "27  <keras.callbacks.History object at 0x7fc0b1976...  \n",
       "28  <keras.callbacks.History object at 0x7fc0b3b0d...  \n",
       "29  <keras.callbacks.History object at 0x7fc0b40d8...  \n",
       "30  <keras.callbacks.History object at 0x7fc0b407e...  \n",
       "31  <keras.callbacks.History object at 0x7fc0b141d...  \n",
       "32  <keras.callbacks.History object at 0x7fc0ac138...  \n",
       "33  <keras.callbacks.History object at 0x7fc08a2e4...  \n",
       "34  <keras.callbacks.History object at 0x7fc08a2a0...  \n",
       "35  <keras.callbacks.History object at 0x7fc08cb20...  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(ALL_RESULTS)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
